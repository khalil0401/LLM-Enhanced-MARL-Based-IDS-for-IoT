# Training Configuration
# MAPPO for IoT IDS

env_config:
  num_agents: 10
  observation_dim: 5000
  max_episode_steps: 1000
  dataset_path: "data/iot23_processed.h5"
  self_play: false  # Set to true for adversarial training

training:
  lr: 3.0e-4
  gamma: 0.99
  lambda: 0.95
  clip_param: 0.2
  train_batch_size: 4096
  sgd_minibatch_size: 128
  num_sgd_iter: 10
  num_workers: 8
  num_gpus: 4  # Adjust based on available hardware
  framework: "torch"
  vf_clip_param: 10.0
  entropy_coeff: 0.01

experiment:
  total_iterations: 1000
  checkpoint_freq: 10
  evaluation_interval: 10
  checkpoint_dir: "checkpoints/mappo"
  wandb_project: "llm-marl-ids"  # Weights & Biases logging
  wandb_entity: "your-entity"

reward_weights:
  detect: 1.0
  fp: -0.5
  latency: -0.2
  resource: -0.1

# Self-play configuration (only used when env_config.self_play = true)
self_play:
  attacker_lr: 1.0e-4
  episodes_per_update: 10
  scenario_generation_freq: 100  # Generate new LLM scenarios every N episodes
  safety_check_freq: 50  # Validate attacker safety every N episodes
  max_attacker_reward: 100.0
